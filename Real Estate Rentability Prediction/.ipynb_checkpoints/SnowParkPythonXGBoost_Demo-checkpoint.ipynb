{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "755c138f",
   "metadata": {},
   "source": [
    "# Machine Learning with Snowpark Python and Java UDFs\n",
    "\n",
    "\n",
    "## Using rental listings we would like to train a ML model to estimate the rent price of our sale listing : \n",
    "\n",
    "![title](img/BusinessUseCase.png)\n",
    "\n",
    "## We will use the following architecture to prepare our data, training our XGBoost linear regression model and run our model on Snowflake :\n",
    "\n",
    "![title](img/TechUseCase.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eb1b66",
   "metadata": {},
   "source": [
    "# Now to the fun stuff !\n",
    "### Imports the Snowpark library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02280f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import *\n",
    "from snowflake.snowpark.functions import *\n",
    "from snowflake.snowpark.types import *\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e7123f",
   "metadata": {},
   "source": [
    "### Initialising our connection to Snowflake "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1653e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Creds.json') as f:\n",
    "    connection_parameters = json.load(f)    \n",
    "\n",
    "mySnowSess = Session.builder.configs(connection_parameters).create()\n",
    "\n",
    "# Clean Stage\n",
    "# mySnowSess.sql(\"rm @SnowParkDemo_Stage\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c22e91",
   "metadata": {},
   "source": [
    "# Data Preparation using Data Frames\n",
    "We have Real Estate listings and their postcodes, what we want to do is to remove outliers. For this we create a dataframe which calculates the median.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e626adca",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADS_df_Raw = mySnowSess.table(\"ADS\").filter(col(\"ADS_CATEGORY_NAME\") ==  \"Locations\" )\n",
    "ADS_df_GrpbyCodeInsee_MedianPrice = ADS_df_Raw.select(\n",
    "  col(\"ADS_CODEINSEE\")\n",
    ", col(\"ADS_ATTR_REAL_ESTATE_TYPE\").as_(\"ADS_ATTR_REAL_ESTATE_TYPE_MEDIAN\")\n",
    ", col(\"ADS_ID\")\n",
    ", (col(\"ADS_PRICE\") / col(\"ADS_ATTR_SQUARE\")).as_(\"ADS_PRICE_SQUARE\")).\\\n",
    "  groupBy(col(\"ADS_CODEINSEE\"),col(\"ADS_ATTR_REAL_ESTATE_TYPE_MEDIAN\")).\\\n",
    "  agg([count (col(\"ADS_ID\")).as_(\"COUNT_ADS\"), median(col(\"ADS_PRICE_SQUARE\")).as_(\"MED_PRICE\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9d41c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ADS_df_GrpbyCodeInsee_MedianPrice.limit(10).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76734211",
   "metadata": {},
   "source": [
    "### Removing outliers\n",
    "We can join our median to our listing data and filter out any listing that deviates too far from the mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b74ced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADS_df_joinMedian = ADS_df_Raw.join(\n",
    "  ADS_df_GrpbyCodeInsee_MedianPrice,\n",
    "  (ADS_df_Raw.col(\"ADS_CODEINSEE\") == ADS_df_GrpbyCodeInsee_MedianPrice.col(\"ADS_CODEINSEE\"))\n",
    "  &(ADS_df_Raw.col(\"ADS_ATTR_REAL_ESTATE_TYPE\") == ADS_df_GrpbyCodeInsee_MedianPrice.col(\"ADS_ATTR_REAL_ESTATE_TYPE_MEDIAN\")))\n",
    "\n",
    "ADS_df_Clean = ADS_df_joinMedian.withColumn(\"ADS_PRICE_SQUARE\", col(\"ADS_PRICE\") / col(\"ADS_ATTR_SQUARE\")).filter(\n",
    "  (col(\"ADS_PRICE_SQUARE\") / (col(\"ADS_PRICE_SQUARE\") + col(\"MED_PRICE\")) >= 0.25)\n",
    "  & (col(\"ADS_PRICE_SQUARE\") / (col(\"ADS_PRICE_SQUARE\") + col(\"MED_PRICE\")) < 0.75)\n",
    "  & (col(\"ADS_PRICE_SQUARE\") < 150)\n",
    "  & (col(\"ADS_PRICE_SQUARE\") > 0)\n",
    "  & (col(\"ADS_ATTR_SQUARE\") >= 9)\n",
    "  & (col(\"ADS_ATTR_SQUARE\") <= 300)\n",
    "  & (col(\"COUNT_ADS\") >= 5)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459f265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ADS_df_Clean.limit(10).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fe929e",
   "metadata": {},
   "source": [
    "### Cleaning the data for data science\n",
    "While having listing types in readable words is useful for the business, it is not ideal for our model training, we create a couple of mapping functions to transform our words to numbers!\n",
    "\n",
    "Snowpark will seamlessly push these functions to snowflake as Python UDFs.\n",
    "\n",
    "**Note:** We would have had to write a SQL CASE statement, but instead we wrote a Python function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2c14cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(name=\"ADS_ATTR_FURNISHED_Encode_Python\", is_permanent=True, stage_location=\"@SnowParkDemo_Stage\", replace=True)\n",
    "def ADS_ATTR_FURNISHED_Encode_Python(x : str) -> int:\n",
    "  if x == \"Meublé\":\n",
    "    return 2\n",
    "  elif x == \"Non meublé\":\n",
    "    return 1\n",
    "  else:\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642d7c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(name=\"ADS_ATTR_REAL_ESTATE_TYPE_Encode_Python\", is_permanent=True, stage_location=\"@SnowParkDemo_Stage\", replace=True)\n",
    "def ADS_ATTR_REAL_ESTATE_TYPE_Encode_Python(x : str) -> int:\n",
    "  if x == \"Maison\":\n",
    "    return 2\n",
    "  elif x == \"Appartement\":\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f5a0ce",
   "metadata": {},
   "source": [
    "Now that these functions are available in snowflake as UDFs we can simply call them from our dataframe to clean our result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbae04d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ADS_df_final = ADS_df_Clean.select(\n",
    "        col('ADS_GEO_LAT')\n",
    "        ,col('ADS_GEO_LNG')\n",
    "        ,col('ADS_ATTR_ROOMS')\n",
    "        ,col('ADS_ATTR_SQUARE')\n",
    "        ,ADS_ATTR_REAL_ESTATE_TYPE_Encode_Python(col(\"ADS_ATTR_REAL_ESTATE_TYPE\")).as_('ADS_ATTR_REAL_ESTATE_TYPE_NUM')\n",
    "        ,ADS_ATTR_FURNISHED_Encode_Python(col(\"ADS_ATTR_FURNISHED\")).as_('ADS_ATTR_FURNISHED_NUM')\n",
    "        ,col('ADS_PRICE'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0ef1ff",
   "metadata": {},
   "source": [
    "We can get the execution plan and SQL needed to prefrom all our steps by calling explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6644363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADS_df_final.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c720b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(ADS_df_final.limit(10).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af24a0d",
   "metadata": {},
   "source": [
    "# Get the prepared data and train the XGBoost Model\n",
    "We cast the retrieve data as dataframe, split these data in training / test dataframe using sklearn and cast them in DMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4894d73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Test / Train\n",
    "CollectedDataframe = pd.DataFrame(ADS_df_final.collect())\n",
    "target = \"ADS_PRICE\"\n",
    "predictors = [x for x in CollectedDataframe.columns if x not in [target]]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(CollectedDataframe[predictors] , CollectedDataframe[target], test_size=0.1)\n",
    "\n",
    "#Create DMatrix\n",
    "import xgboost as xgb\n",
    "DMatrix_train = xgb.DMatrix(X_train, label=y_train)\n",
    "DMatrix_test = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "print(\"DMatrix_train (\", DMatrix_train.num_row() ,\", \",DMatrix_train.num_col(),\")\")\n",
    "print(\"DMatrix_test  (\", DMatrix_test.num_row()  ,\", \",DMatrix_test.num_col(),\")\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ef3bf3",
   "metadata": {},
   "source": [
    "We setup the XGBoost parameters for the training and run the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b6fa29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param={}\n",
    "param['booster']='gbtree'\n",
    "param['objective']= 'reg:squarederror'\n",
    "param['eta']=0.05\n",
    "param['max_depth']=10\n",
    "param['min_child_weight']=1\n",
    "param['gamma']=1\n",
    "param['subsample']=0.75\n",
    "param['colsample_bytree']=0.75\n",
    "param['scale_pos_weight']=1\n",
    "param['nthread'] = -1\n",
    "param['verbosity'] = 1\n",
    "\n",
    "\n",
    "evallist = [(DMatrix_train, 'train'), (DMatrix_test, 'eval')]\n",
    "num_round=100\n",
    "bst = xgb.train(param, DMatrix_train, num_round, evallist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4035bc18",
   "metadata": {},
   "source": [
    "Print the features importance and the variance Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83edca8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "xgb.plot_importance(bst)\n",
    "\n",
    "# make predictions for test data\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "pred_test = bst.predict(DMatrix_test)\n",
    "print(\"pred_test : \", explained_variance_score(pred_test,DMatrix_test.get_label()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadbbd75",
   "metadata": {},
   "source": [
    "# Creating the Python Inference function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d609f95",
   "metadata": {},
   "source": [
    "### Register the Python Inference Function as Python UDF on Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34edb822",
   "metadata": {},
   "outputs": [],
   "source": [
    "mySnowSess.add_packages(\"xgboost\",\"pandas\")\n",
    "\n",
    "@udf(name=\"get_XGBoost_RENT_PRICE_New\", is_permanent=True, stage_location=\"@SnowParkDemo_Stage\", replace=True)\n",
    "def get_XGBoost_RENT_PRICE(lat: float, lng: float, rooms: int, square: float, realestatetype: int, furnished: int) -> float:\n",
    "    import pandas\n",
    "    import xgboost as xgb\n",
    "    RowDataFrame = pandas.DataFrame([[lat, lng, rooms, square, realestatetype, furnished]],columns=['ADS_GEO_LAT', 'ADS_GEO_LNG', 'ADS_ATTR_ROOMS', 'ADS_ATTR_SQUARE', 'ADS_ATTR_REAL_ESTATE_TYPE_NUM', 'ADS_ATTR_FURNISHED_NUM'])\n",
    "    RowDMatrix = xgb.DMatrix(RowDataFrame)\n",
    "    return bst.predict(RowDMatrix)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abeef178",
   "metadata": {},
   "source": [
    "# Using our UDF Function to run our model on Snowflake "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06868514",
   "metadata": {},
   "source": [
    "### Classifying our entire data and writing it to a new table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e26d309",
   "metadata": {},
   "outputs": [],
   "source": [
    "mySnowSess.table(\"LBC.PUBLIC.LBC_ADS\").filter((col(\"ADS_CATEGORY_NAME\") ==  \"Ventes immobilières\" )). \\\n",
    "    withColumn(\"EstimatedRentPrice\",get_XGBoost_RENT_PRICE(\n",
    "        col(\"ADS_GEO_LAT\"),\n",
    "        col(\"ADS_GEO_LNG\"),\n",
    "        col(\"ADS_ATTR_ROOMS\"),\n",
    "        col(\"ADS_ATTR_SQUARE\"),\n",
    "        ADS_ATTR_REAL_ESTATE_TYPE_Encode_Python(col(\"ADS_ATTR_REAL_ESTATE_TYPE\")),\n",
    "        ADS_ATTR_FURNISHED_Encode_Python(col(\"ADS_ATTR_FURNISHED\")))).\\\n",
    "    write.mode(\"overwrite\").saveAsTable(\"LBC_ADS_RENT_PRED_XGBOOST\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2696bb",
   "metadata": {},
   "source": [
    "### Alternatively, use our Classifier on demand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f706f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(mySnowSess.table(\"LBC.PUBLIC.LBC_ADS\").filter((col(\"ADS_CATEGORY_NAME\") ==  \"Ventes immobilières\" )). \\\n",
    "    withColumn(\"EstimatedRentPrice\",get_XGBoost_RENT_PRICE(\n",
    "        col(\"ADS_GEO_LAT\"),\n",
    "        col(\"ADS_GEO_LNG\"),\n",
    "        col(\"ADS_ATTR_ROOMS\"),\n",
    "        col(\"ADS_ATTR_SQUARE\"),\n",
    "        ADS_ATTR_REAL_ESTATE_TYPE_Encode_Python(col(\"ADS_ATTR_REAL_ESTATE_TYPE\")),\n",
    "        ADS_ATTR_FURNISHED_Encode_Python(col(\"ADS_ATTR_FURNISHED\")))). \\\n",
    "select(col(\"ADS_SUBJECT\"),col(\"ADS_GEO_CITY\"),col(\"EstimatedRentPrice\"),col(\"ADS_PRICE\")).limit(10).collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8171cab8",
   "metadata": {},
   "source": [
    "### Optional :  We can also write the model to file and push it on Snowflake for A/B Testing UDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4687bd",
   "metadata": {},
   "source": [
    "create or replace function GetLocPriceXGBoostABTest(model VARCHAR, lat  FLOAT, lng  FLOAT, rooms  NUMBER, square FLOAT, realestatetype  NUMBER, furnished  NUMBER)\n",
    "returns FLOAT\n",
    "language python\n",
    "runtime_version = '3.8'\n",
    "packages = ('xgboost', 'pandas')\n",
    "imports=('@snowparkdemo_stage/AnnoncePriceLocations_A.xbmodel','@snowparkdemo_stage/AnnoncePriceLocations_B.xbmodel')\n",
    "handler = 'GetLocPriceXGBoost'\n",
    "as\n",
    "$$\n",
    "import sys\n",
    "IMPORT_DIRECTORY_NAME = \"snowflake_import_directory\"\n",
    "import_dir = sys._xoptions[IMPORT_DIRECTORY_NAME]\n",
    "\n",
    "def GetLocPriceXGBoost(model: str, lat: float, lng: float, rooms: int, square: float, realestatetype: int, furnished: int):\n",
    "    import pandas\n",
    "    import xgboost as xgb\n",
    "    file_path = import_dir + \"AnnoncePriceLocations_\" + model + \".xbmodel\"\n",
    "    bst = xgb.Booster({'nthread': 1})  # init model\n",
    "    bst.load_model(file_path)\n",
    "    RowDataFrame = pandas.DataFrame([[lat, lng, rooms, square, realestatetype, furnished]],columns=['ADS_GEO_LAT', 'ADS_GEO_LNG', 'ADS_ATTR_ROOMS', 'ADS_ATTR_SQUARE', 'ADS_ATTR_REAL_ESTATE_TYPE_NUM', 'ADS_ATTR_FURNISHED_NUM'])\n",
    "    RowDMatrix = xgb.DMatrix(RowDataFrame)\n",
    "    return bst.predict(RowDMatrix)[0]\n",
    "\n",
    "$$;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6660fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bst.save_model(\"./AnnoncePriceLocations_A.xbmodel\")\n",
    "#mySnowSess.sql(\"put file:///Users/apicard/Documents/SnowFlake/Project/SnowParkPython/Project_1/SnowparkDemo/snowpark-python-xgboost-realestate/AnnoncePriceLocations_A.xbmodel @SnowParkDemo_Stage overwrite=true\").collect()\n",
    "\n",
    "#bst.save_model(\"./AnnoncePriceLocations_B.xbmodel\")\n",
    "#mySnowSess.sql(\"put file:///Users/apicard/Documents/SnowFlake/Project/SnowParkPython/Project_1/SnowparkDemo/snowpark-python-xgboost-realestate/AnnoncePriceLocations_B.xbmodel @SnowParkDemo_Stage overwrite=true\").collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8550216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mySnowSess.close();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
