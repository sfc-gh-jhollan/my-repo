{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42ae31ab",
   "metadata": {},
   "source": [
    "#  Credit Scoring with Snowpark for Python\n",
    "Author: Zohar Nissare-Houssen\n",
    "\n",
    "In this notebook, we are going to use the [Snowpark](https://dhttps://docs.snowflake.com/en/developer-guide/snowpark/reference/python/index.html) Python API and Python UDFs to run through a credit card scoring demo.\n",
    "\n",
    "In this scenario, Snowbank wants to use their existing credit files to analyze the current credit standings on whether the loans are being paid without any issues, and/or if there are any delays/default. \n",
    "\n",
    "Based on the current credit standing, Snowbank wants to build a machine learning credit scoring algorithm based on the dataset to be able to automate an assessment on whether a loan should be approved or declined.\n",
    "\n",
    "## Prerequisite\n",
    "\n",
    "Please run the Credit Scoring Demo Setup Notebook prior to running this demo.\n",
    "\n",
    "This version requires Snowpark **0.6.0** or higher"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc31424",
   "metadata": {},
   "source": [
    "## 1. Data Exploration\n",
    "\n",
    "In this section, we will explore the dataset for the existing credits on file.\n",
    "\n",
    "### 1.1 Opening a Snowflake Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90375742",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import *\n",
    "from snowflake.snowpark import version\n",
    "from snowflake.snowpark.functions import *\n",
    "\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae30bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/jovyan/work/creds.json') as f:\n",
    "    connection_parameters = json.load(f)    \n",
    "\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "\n",
    "print(session.sql(\"select current_warehouse(), current_database(), current_schema(), current_user(), current_role()\").collect())\n",
    "\n",
    "# Print the current version of the Snowpark library\n",
    "print(version.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eeb0be",
   "metadata": {},
   "source": [
    "### 1.2 The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba74d6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df = session.table(\"CREDIT_FILES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448315f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df.describe().toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e8f472",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df.toPandas().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140d1b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45099fdf",
   "metadata": {},
   "source": [
    "### 1.3  Visualizing the Numeric Features\n",
    "\n",
    "From this visualization, we can see a few interesting characteristics:\n",
    "\n",
    "* Most of the credit requests are for small amounts (< 50k)\n",
    "* Most of the credit terms are 20 months or less.\n",
    "* Most of the applicants have a very good credit score.\n",
    "* Most of the applicants do not have a lot of balance in either credits or savings with Snowbank.\n",
    "* Most of the applicants are less than 40 years old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f81956c",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_df.toPandas().hist(figsize=(15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bde95d4",
   "metadata": {},
   "source": [
    "### 1.4  Visualizing the Categorical Features\n",
    "\n",
    "From this visualization, we can see a few interesting characteristics:\n",
    "\n",
    "* Most of the popular credit requests are related to either a vehicle purchase or consumer goods.\n",
    "* The vast majority of loans do not have guarantors, nor co-applicants.\n",
    "* Most of credit in file is in good standing.\n",
    "* The majority of the applicants are male, foreign workers, and skilled who own their own house/apartment.\n",
    "* Higher amounts of loans (which threshold varies per category of loan) have a higher chance of defaulting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ff5f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(5, 2, figsize=(15, 30))\n",
    "df = credit_df.toPandas()\n",
    "sns.countplot(data=df, y=\"PURPOSE\", ax=axs[0,0])\n",
    "sns.countplot(data=df, x=\"OTHER_PARTIES\", ax=axs[0,1])\n",
    "sns.countplot(data=df, x=\"CREDIT_STANDING\", ax=axs[1,0])\n",
    "sns.countplot(data=df, x=\"ASSETS\", ax=axs[1,1])\n",
    "sns.countplot(data=df, x=\"HOUSING\", ax=axs[2,0])\n",
    "sns.countplot(data=df, x=\"QUALIFICATION\", ax=axs[2,1])\n",
    "sns.countplot(data=df, x=\"SEX\", ax=axs[3,0])\n",
    "sns.countplot(data=df, x=\"MARITAL_STATUS\", ax=axs[3,1])\n",
    "sns.countplot(data=df, x=\"OTHER_PAYMENT_PLANS\", ax=axs[4,0])\n",
    "sns.stripplot(y=\"PURPOSE\", x=\"CREDIT_AMOUNT\", data=df, hue='CREDIT_STANDING', jitter=True, ax=axs[4,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65f1afc",
   "metadata": {},
   "source": [
    "### 1.5 Running queries through Snowpark API\n",
    "\n",
    "We can use the Snowpark API to run queries to get various insights. For example, let's try to determine the range of f loans per different category. We can check the Snowflake query history and review how the Snowpark API has been pushed down as SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb29ef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loan_status = credit_df.select(col(\"PURPOSE\"),col(\"CREDIT_AMOUNT\"))\\\n",
    "                          .groupBy(col(\"PURPOSE\"))\\\n",
    "                          .agg([min(col(\"CREDIT_AMOUNT\")).as_(\"MIN_CREDIT_AMOUNT\"), max(col(\"CREDIT_AMOUNT\")).as_(\"MAX_CREDIT_AMOUNT\"), median(col(\"CREDIT_AMOUNT\")).as_(\"MED_CREDIT_AMOUNT\"),avg(col(\"CREDIT_AMOUNT\")).as_(\"AVG_CREDIT_AMOUNT\")])\\\n",
    "                          .sort(col(\"PURPOSE\"))\n",
    "df_loan_status.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e89dfd",
   "metadata": {},
   "source": [
    "## 2. Data Transformation and Encoding\n",
    "\n",
    "\n",
    "For the current use case, in order to prepare the data for machine learning, we need to encode the categorical values into numerical. \n",
    "\n",
    "In order to achieve this, we can leverage Snowflake compute by defining Python UDFs in order to perform the encoding.\n",
    "\n",
    "### 2.1 Encoding Categorical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b50b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql(\"create or replace stage fnstage encryption = (type = 'SNOWFLAKE_SSE')\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4674fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(name=\"PURPOSE_Encode\", is_permanent=True, stage_location=\"@fnstage\", replace=True, session=session)\n",
    "def Purpose_Encode(x : str) -> int:\n",
    "  if x == \"Consumer Goods\":\n",
    "    return 1\n",
    "  elif x == \"Vehicle\":\n",
    "    return 2\n",
    "  elif x == \"Tuition\":\n",
    "    return 3\n",
    "  elif x == \"Business\":\n",
    "    return 4\n",
    "  elif x == \"Repairs\":\n",
    "    return 5\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "@udf(name=\"OTHER_PARTIES_Encode\", is_permanent=True, stage_location=\"@fnstage\", replace=True, session=session)\n",
    "def Other_Parties_Encode(x : str) -> int:\n",
    "  if x == \"Guarantor\":\n",
    "    return 1\n",
    "  elif x == \"Co-Applicant\":\n",
    "    return 2\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "@udf(name=\"CREDIT_STANDING_Encode\", is_permanent=True, stage_location=\"@fnstage\", replace=True, session=session)\n",
    "def Credit_Standing_Encode(x : str) -> int:\n",
    "  if x == \"good\":\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "@udf(name=\"ASSETS_Encode\", is_permanent=True, stage_location=\"@fnstage\", replace=True, session=session)\n",
    "def Assets_Encode(x : str) -> int:\n",
    "  if x == \"Vehicle\":\n",
    "    return 1\n",
    "  elif x == \"Investments\":\n",
    "    return 2\n",
    "  elif x == \"Home\":\n",
    "    return 3\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "@udf(name=\"HOUSING_Encode\", is_permanent=True, stage_location=\"@fnstage\", replace=True, session=session)\n",
    "def Housing_Encode(x : str) -> int:\n",
    "  if x == \"rent\":\n",
    "    return 1\n",
    "  elif x == \"own\":\n",
    "    return 2\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "@udf(name=\"QUALIFICATION_Encode\", is_permanent=True, stage_location=\"@fnstage\", replace=True, session=session)\n",
    "def Qualification_Encode(x : str) -> int:\n",
    "  if x == \"unskilled\":\n",
    "    return 1\n",
    "  elif x == \"skilled\":\n",
    "    return 2\n",
    "  elif x == \"highly skilled\":\n",
    "    return 3\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "@udf(name=\"SEX_Encode\", is_permanent=True, stage_location=\"@fnstage\", replace=True, session=session)\n",
    "def Sex_Encode(x : str) -> int:\n",
    "  if x == \"M\":\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "@udf(name=\"MARITAL_STATUS_Encode\", is_permanent=True, stage_location=\"@fnstage\", replace=True, session=session)\n",
    "def Marital_Status_Encode(x : str) -> int:\n",
    " if x == \"Married\":\n",
    "    return 1\n",
    " elif x == \"Single\":\n",
    "    return 2\n",
    " else:\n",
    "    return 0\n",
    "\n",
    "\n",
    "@udf(name=\"OTHER_PAYMENT_PLANS_Encode\", is_permanent=True, stage_location=\"@fnstage\", replace=True, session=session)\n",
    "def Other_Payment_Plans_Encode(x : str) -> int:\n",
    "  if x == \"bank\":\n",
    "    return 1\n",
    "  elif x == \"stores\":\n",
    "    return 2\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "@udf(name=\"CREDIT_SCORE_Decode\", is_permanent=True, stage_location=\"@fnstage\", replace=True, session=session)\n",
    "def Credit_Score_Decode(x : int) -> str:\n",
    "  if x == 1:\n",
    "    return \"Approved\"\n",
    "  else:\n",
    "    return \"Denied\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512ab632",
   "metadata": {},
   "source": [
    "We can invoke the UDF through the Snowpark API as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87865f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=credit_df.select(col(\"PURPOSE\"), \\\n",
    "                    Purpose_Encode(col(\"PURPOSE\")).as_(\"PURPOSE_ENCODED\")) \\\n",
    "                    .groupBy(col(\"PURPOSE\"),col(\"PURPOSE_ENCODED\")) \\\n",
    "                    .agg((count(\"PURPOSE\")).alias(\"COUNT\"))\n",
    "\n",
    "df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3931bfd",
   "metadata": {},
   "source": [
    "We could use the UDFs just created within Snowflake through SQL as follows\n",
    ">```sql\n",
    "select 'Tuition' as PURPOSE, PURPOSE_Encode('Tuition') as PURPOSE_CODE;\n",
    ">```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162c8c49",
   "metadata": {},
   "source": [
    "### 2.2 Decoding an integer value using a vectorized UDF\n",
    "\n",
    "We also want to create a decoding function mapping the output of our machine learning model to a string, on whether a credit request has been approved or denied. For this, we want to demonstrate with a simple example the use of a vectorized UDF. \n",
    "\n",
    "Compared to the default row-by-row processing pattern of a normal UDF, which sometimes is inefficient, a vectorized UDF allows vectorized operations on a dataframe, with the input as a Pandas DataFrame or Pandas Series. In a vectorized UDF, you can operate on a batches of rows by handling Pandas DataFrame or Pandas Series.\n",
    "\n",
    "As you can see in the example below, we pass in as a parameter a Pandas series corresponding to the value of the columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcaa721",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.types import PandasSeries, PandasDataFrame \n",
    "\n",
    "@udf(name=\"CREDIT_SCORE_Decode\", is_permanent=True, stage_location=\"@fnstage\", replace=True, session=session)\n",
    "def Credit_Score_Decode(series: PandasSeries[int])-> PandasSeries[str]:\n",
    "    return series.apply(lambda x: \"Approved\" if (x == 1) else \"Denied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5405fa8e",
   "metadata": {},
   "source": [
    "Let's try to test the UDF previously created by passing a Pandas series with 3 values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9e52e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = session.createDataFrame([1,0,1]).to_df(\"a\")\n",
    "\n",
    "df1.select(Credit_Score_Decode(\"a\")).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cd5a44",
   "metadata": {},
   "source": [
    "### 2.3 Preparing the Feature Matrix for ML\n",
    "\n",
    "In this section, we are going to leverage the Snowpark Python API, along with the Python UDFs that we just created previously in order to prepare a feature matrix for a Random Forest Classifier Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284f8708",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = credit_df.select(\n",
    "                                   Purpose_Encode(col(\"PURPOSE\")).as_(\"PURPOSE_CODE\"), \n",
    "                                   Qualification_Encode(col(\"QUALIFICATION\")).as_(\"QUALIFICATION_CODE\"), \n",
    "                                   Other_Parties_Encode(col(\"OTHER_PARTIES\")).as_(\"OTHER_PARTIES_CODE\"),\n",
    "                                   Other_Payment_Plans_Encode(col(\"OTHER_PAYMENT_PLANS\")).as_(\"OTHER_PAYMENT_PLANS_CODE\"),\n",
    "                                   Housing_Encode(col(\"HOUSING\")).as_(\"HOUSING_CODE\"),\n",
    "                                   Assets_Encode(col(\"ASSETS\")).as_(\"ASSETS_CODE\"),\n",
    "                                   Sex_Encode(col(\"SEX\")).as_(\"SEX_CODE\"),\n",
    "                                   Marital_Status_Encode(col(\"MARITAL_STATUS\")).as_(\"MARITAL_STATUS_CODE\"),\n",
    "                                   Credit_Standing_Encode(col(\"CREDIT_STANDING\")).as_(\"CREDIT_STANDING_CODE\"),\n",
    "                                   col(\"CHECKING_BALANCE\"),\n",
    "                                   col(\"SAVINGS_BALANCE\"),\n",
    "                                   col(\"AGE\"),\n",
    "                                   col(\"JOB_HISTORY\"),\n",
    "                                   col(\"CREDIT_SCORE\"),\n",
    "                                   col(\"CREDIT_DURATION\"), \n",
    "                                   col(\"CREDIT_AMOUNT\"),\n",
    "                                   col(\"RESIDENCE_SINCE\"),\n",
    "                                   col(\"INSTALLMENT_COMMITMENT\"),\n",
    "                                   col(\"NUM_DEPENDENTS\"),\n",
    "                                   col(\"EXISTING_CREDITS\")\n",
    "                                 )                                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ededa52",
   "metadata": {},
   "source": [
    "Now that the feature matrix has been defined, we will convert it into a Pandas Dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5dac75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = feature_matrix.toPandas().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8f73b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c84d496",
   "metadata": {},
   "source": [
    "This is what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca42631a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9a5fec",
   "metadata": {},
   "source": [
    "## 3. Random Forest Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518b5726",
   "metadata": {},
   "source": [
    "We are going to leverage the Random Forest Classifier Model available as part of the scikit-learn popular ML Library available in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52e03fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('CREDIT_STANDING_CODE',axis=1), \n",
    "                                                    df['CREDIT_STANDING_CODE'], test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe48926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fdafe4",
   "metadata": {},
   "source": [
    "## 4. Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470ca6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pred = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8b04d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828a963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386a1b07",
   "metadata": {},
   "source": [
    "As we are seeing a good performance for the model in terms of precision for predicting 0 -> Loan Denial, Snowbank wants to operationalize the model within their Snowflake environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cf3e4b",
   "metadata": {},
   "source": [
    "## 5. Export the Model within a Python UDF for Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0384cf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "dump(rfc, './credit_score.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbeea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.file.put(\"credit_score.joblib\", \"@fnstage\", auto_compress=False, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e25c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.clear_imports()\n",
    "session.add_import(\"@fnstage/credit_score.joblib\")\n",
    "#session.add_packages(\"joblib\", \"pandas\", \"scikit-learn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de25d922",
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(name = 'credit_score', is_permanent = True, replace = True, stage_location = '@FNSTAGE', session = session, \n",
    "     packages=[\"joblib\",\"pandas\",\"scikit-learn\"])\n",
    "def credit_score(arg: list) -> int:\n",
    "    import joblib\n",
    "    import sys\n",
    "    import pandas as pd\n",
    "\n",
    "    IMPORT_DIRECTORY_NAME = \"snowflake_import_directory\"\n",
    "    import_dir = sys._xoptions[IMPORT_DIRECTORY_NAME]\n",
    "    pipe_file = import_dir + 'credit_score.joblib'\n",
    "        \n",
    "    pipeline = joblib.load(pipe_file)\n",
    "    row = pd.DataFrame([arg], columns=[ 'PURPOSE_CODE',\n",
    "                                        'QUALIFICATION_CODE',\n",
    "                                        'OTHER_PARTIES_CODE',\n",
    "                                        'OTHER_PAYMENT_PLANS_CODE',\n",
    "                                        'HOUSING_CODE',\n",
    "                                        'ASSETS_CODE',\n",
    "                                        'SEX_CODE',\n",
    "                                        'MARITAL_STATUS_CODE',\n",
    "                                        'CHECKING_BALANCE',\n",
    "                                        'SAVINGS_BALANCE',\n",
    "                                        'AGE',\n",
    "                                        'JOB_HISTORY',\n",
    "                                        'CREDIT_SCORE',\n",
    "                                        'CREDIT_DURATION',\n",
    "                                        'CREDIT_AMOUNT',\n",
    "                                        'RESIDENCE_SINCE',\n",
    "                                        'INSTALLMENT_COMMITMENT',\n",
    "                                        'NUM_DEPENDENTS',\n",
    "                                        'EXISTING_CREDITS'])           \n",
    "    return pipeline.predict(row)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b4747e",
   "metadata": {},
   "source": [
    "## 6. Performing Inference in Snowflake\n",
    "\n",
    "In the example below, we want to process an existing batch of 60 credit pending requests and provide an assessment on whether the loan should be approved or denied. The data looks like as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3de0261",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cred_req = session.table(\"CREDIT_REQUESTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52d63f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cred_req.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82614dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c64676e",
   "metadata": {},
   "source": [
    "### 6.1 Develop Stored Procedure for scoring\n",
    "\n",
    "As the bank receives the credit requests in near real-time, we want to write a stored procedure which could be called through a task to score micro-batches of requests as they come in. \n",
    "\n",
    "The Python stored procedure will first build the input features for the model using the Snowpark API and invoke the Python UDF we built earlier for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46fb14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.add_packages('snowflake-snowpark-python')\n",
    "\n",
    "@sproc(name=\"process_credit_requests\", replace=True, is_permanent=True, stage_location=\"@fnstage\")\n",
    "def process_credit_requests_fn (session: snowflake.snowpark.Session, credit_requests: str, credit_assessment: str) -> int:\n",
    "    \n",
    "    #Build the input features for the model using the Snowpark API as well as the Python UDFs for encoding.\n",
    "    df_cred_req = session.table(credit_requests).select( \n",
    "                            col(\"CREDIT_REQUEST_ID\"), col(\"PURPOSE\"), \n",
    "                            Purpose_Encode(col(\"PURPOSE\")).as_(\"PURPOSE_CODE\"),\n",
    "                            Qualification_Encode(col(\"QUALIFICATION\")).as_(\"QUALIFICATION_CODE\"),\n",
    "                            Other_Parties_Encode(col(\"OTHER_PARTIES\")).as_(\"OTHER_PARTIES_CODE\"),\n",
    "                            Other_Payment_Plans_Encode(col(\"OTHER_PAYMENT_PLANS\")).as_(\"OTHER_PAYMENT_PLANS_CODE\"),\n",
    "                            Housing_Encode(col(\"HOUSING\")).as_(\"HOUSING_CODE\"),\n",
    "                            Assets_Encode(col(\"ASSETS\")).as_(\"ASSETS_CODE\"),\n",
    "                            Sex_Encode(col(\"SEX\")).as_(\"SEX_CODE\"),\n",
    "                            Marital_Status_Encode(col(\"MARITAL_STATUS\")).as_(\"MARITAL_STATUS_CODE\"),\n",
    "                            col(\"CHECKING_BALANCE\"),\n",
    "                            col(\"SAVINGS_BALANCE\"),\n",
    "                            col(\"AGE\"),\n",
    "                            col(\"JOB_HISTORY\"),\n",
    "                            col(\"CREDIT_SCORE\"),\n",
    "                            col(\"CREDIT_DURATION\"), \n",
    "                            col(\"CREDIT_AMOUNT\"), \n",
    "                            col(\"RESIDENCE_SINCE\"),\n",
    "                            col(\"INSTALLMENT_COMMITMENT\"),\n",
    "                            col(\"NUM_DEPENDENTS\"),\n",
    "                            col(\"EXISTING_CREDITS\")\n",
    "                         )\n",
    "    \n",
    "    #Call the UDF to score the existing credit requests read previously    \n",
    "    input_features = [ 'PURPOSE_CODE',\n",
    "                   'QUALIFICATION_CODE',\n",
    "                   'OTHER_PARTIES_CODE',\n",
    "                   'OTHER_PAYMENT_PLANS_CODE',\n",
    "                   'HOUSING_CODE',\n",
    "                   'ASSETS_CODE',\n",
    "                   'SEX_CODE',\n",
    "                   'MARITAL_STATUS_CODE',\n",
    "                   'CHECKING_BALANCE',\n",
    "                   'SAVINGS_BALANCE',\n",
    "                   'AGE',\n",
    "                   'JOB_HISTORY',\n",
    "                   'CREDIT_SCORE',\n",
    "                   'CREDIT_DURATION',\n",
    "                   'CREDIT_AMOUNT',\n",
    "                   'RESIDENCE_SINCE',\n",
    "                   'INSTALLMENT_COMMITMENT',\n",
    "                   'NUM_DEPENDENTS',\n",
    "                   'EXISTING_CREDITS']           \n",
    "\n",
    "    df_assessment = df_cred_req.select(col(\"CREDIT_REQUEST_ID\"), col(\"PURPOSE\"), col(\"CREDIT_AMOUNT\"), col(\"CREDIT_DURATION\"),\n",
    "                    call_udf(\"credit_score_decode\",(call_udf(\"credit_score\", array_construct(*input_features)))).as_(\"CREDIT_STATUS\"))\n",
    "    \n",
    "    df_assessment.write.mode(\"overwrite\").saveAsTable(credit_assessment)\n",
    "    \n",
    "    #The stored procedure will return the total number of credit request assessed.\n",
    "    return df_assessment.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268f1a63",
   "metadata": {},
   "source": [
    "### 6.2 Invoking the Stored Procedure for scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75637b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.call(\"process_credit_requests\", \"credit_requests\", \"credit_assessments\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e93be6",
   "metadata": {},
   "source": [
    "We could run this query directy from Snowflake as follows\n",
    "\n",
    ">```sql\n",
    "CALL process_credit_requests ('credit_requests', 'credit_assessments');\n",
    ">```\n",
    "\n",
    "Let's now take a look at the credit_assessments table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc04f48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.table(\"credit_assessments\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264a22cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pysnowpark",
   "language": "python",
   "name": "pysnowpark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
