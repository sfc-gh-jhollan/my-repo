{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d0a5246-4cb5-474e-820f-94decc87377c",
   "metadata": {},
   "source": [
    "# udf_transform examples\n",
    "\n",
    "This notebook demonstrates of how to use the **udf_transform** module.\n",
    "\n",
    "The primary purpose of **udf_transform** is to be able to use the encoders/scalers created by the **preprocessing** module where the Snowpark DataFrame API can not be used. It could be that the transformation would be done using only SQL.\n",
    "\n",
    "This notebook has two parts\n",
    "1) Showing how to use the diffirent transform and inverse functions for UDFs\n",
    "2) Showing how to use them in Python UDFs (scalar and tabular)\n",
    "\n",
    "## Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff15df4c-57b8-4d18-83b9-6bc1a27c37fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "import snowflake.snowpark.functions as F\n",
    "import snowflake.snowpark.types as T\n",
    "\n",
    "import cachetools\n",
    "\n",
    "# Print the version of Snowpark we are using\n",
    "from importlib.metadata import version\n",
    "version('snowflake_snowpark_python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21646e7b-e122-49f1-89b7-6dff07e023ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e7e352-8776-4d31-b0cc-dbf1de07481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing as pp\n",
    "import udf_transform as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d48b159-9e0b-4261-a695-32e7d81fae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_parameters = {\n",
    "    \"account\": \"MY DEMO ACCOUNT\",\n",
    "    \"user\": \"MY USER\",\n",
    "    \"password\": \"MY PASSWORD\",\n",
    "    \"warehouse\": \"MY COMPUTE WH\",\n",
    "    \"database\": \"MY DATABASE\",\n",
    "    \"schema\": \"MY SCHEMA\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76235800-1d2f-46f2-a7ef-ccee4c024017",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session.builder.configs(connection_parameters).create()\n",
    "print(\"Current role: \" + session.get_current_role() + \", Current schema: \" + session.get_fully_qualified_current_schema() + \", Current WH: \" + session.get_current_warehouse())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d650044-fe5d-4e00-8e74-cf1190cfa0cb",
   "metadata": {},
   "source": [
    "Start by creating a dataset that can be used for both scaling and encoding.\n",
    "\n",
    "By caching the result into a new dataframe we avoid running teh generation SQL every time the data frame is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb092658-582a-41e7-a3f5-efdfbeb520a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = '[\"AK\", \"AL\", \"AR\", \"AZ\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \"HI\", \"IA\", \"ID\", \"IL\", \"IN\", \"KS\", \"KY\", \"LA\", \"MA\", \"MD\", \"ME\", \"MI\", \"MN\", \"MO\", \"MS\", \"MT\", \"NC\", \"ND\", \"NE\", \"NH\", \"NJ\", \"NM\", \"NV\", \"NY\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \"VA\", \"VT\", \"WA\", \"WI\", \"WV\", \"WY\"]'\n",
    "area_code = '[408, 415, 510]'\n",
    "intl_plan =  '[\"no\", \"yes\"]'\n",
    "\n",
    "df_gen_data = session.range(1000).with_columns([\"STATES\", \"AREA_CODES\", \"INTL_PLANS\"], \n",
    "                                         [F.parse_json(F.lit(state)), F.parse_json(F.lit(area_code)), F.parse_json(F.lit(intl_plan))])\\\n",
    "                            .select(F.col(\"ID\").as_(\"CUST_ID\"), F.as_varchar(F.get(F.col(\"STATES\"), (F.call_builtin(\"zipf\", F.lit(1), F.lit(51), F.random()) -1))).as_(\"STATE\"),\\\n",
    "                                    F.get(F.col(\"AREA_CODES\"), (F.call_builtin(\"zipf\", F.lit(1), F.lit(3), F.random())) -1).as_(\"AREA_CODE\"),\\\n",
    "                                    F.as_varchar(F.get(F.col(\"INTL_PLANS\"), (F.call_builtin(\"zipf\", F.lit(1), F.lit(2), F.random()))-1)).as_(\"INTL_PLAN\"),\\\n",
    "                                    F.uniform(0, 100, F.random()).as_(\"CALLS\"), F.uniform(0, 100, F.random()).as_(\"MINS\"),F.uniform(0, 100, F.random()).as_(\"DATA\"),\\\n",
    "                                    F.uniform(0.5, 10.9, F.random()).as_(\"DAY_CHARGE\"),F.uniform(5.5, 15.1, F.random()).as_(\"INTL_CHARGE\"))\n",
    "\n",
    "df_test = df_gen_data.cache_result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e509745-c9f7-45c8-8936-4f4c3f47c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc85055-034d-4f45-a561-87335f9f41da",
   "metadata": {},
   "source": [
    "## Introduction to the udf_transform functions\n",
    "The purpose of the **udf_transform** module is to be able to use the encoders/scalers created by using the **preprocessing** module on Snowpark DataFrames where we do not can use Snowpark DataFrames, for example when the transformation is to be done with only SQL.\n",
    "\n",
    "The **udf_transform** module has a transformer function for all scalers/encoders and in many canses also functions to inverse the scaling/encoding.\n",
    "\n",
    "For each scaler and encoder in **preprocessing** there is a function in **udf_transform** to do the transformation based the fitted values.\n",
    "### Scalers\n",
    "**udf_transform** has the following functions for Scalers:\n",
    "* udf_minmax_transform\n",
    "* udf_minmax_inverse_transform\n",
    "* udf_standard_transform\n",
    "* udf_standard_inverse_transform\n",
    "* udf_maxabs_transform\n",
    "* udf_maxabs_inverse_transform\n",
    "* udf_robust_transform\n",
    "* udf_robust_inverse_transform\n",
    "* udf_normalizer_transform\n",
    "* udf_binarizer_transform\n",
    "\n",
    "Input data can be a list or a numpy array.\n",
    "\n",
    "Start by generating data to use with the scalers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23f98d1-e8ee-43c9-a81b-b26199fb1b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_test = [[86, 10.2665], [34, 2.2345], [13, 8.1465], [66, 7.45]]\n",
    "scaler_input_cols=[\"CALLS\", \"DAY_CHARGE\"]\n",
    "scaler_output_cols = [\"calls_scaled\", \"day_charge_scaled\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7eb96b-0f1f-47f9-a442-fca34ae29ccf",
   "metadata": {},
   "source": [
    "#### udf_minmax_transform\n",
    "\n",
    "\n",
    "Start by fitting a Scaler using the **preprocessing** module, once fitted we can use the **get_udf_encoder** method to get a dictornary that can be used for transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa7d076-cb4c-4369-94d3-345dbd9a711e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = pp.MinMaxScaler(input_cols=scaler_input_cols, output_cols=scaler_output_cols)\n",
    "mms.fit(df_test)\n",
    "mms_udf = mms.get_udf_encoder()\n",
    "mms_udf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6e7608-04a5-46db-b81a-619bafe81ce6",
   "metadata": {},
   "source": [
    "Using the **udf_minmax_transform** will scale a list of list (one list for each row) using the fitted values in **mms_udf** and return a list of the same shape as the input list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cea0397-03d1-4a5c-bcd7-dd2dff1cac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "mms_encoded_data = ut.udf_minmax_transform(array_test, mms_udf)\n",
    "mms_encoded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a4f9b4-610b-4c00-8cf8-9aca95fb3bb1",
   "metadata": {},
   "source": [
    "**udf_minmax_inverse_transform** will inverse the scaled data back to original values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a008e7dc-bb88-4e40-b1b9-6308d0cb6731",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.udf_minmax_inverse_transform(mms_encoded_data, mms_udf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a5aa5a-adde-4712-b2b3-c5d08fa9a62c",
   "metadata": {},
   "source": [
    "#### udf_standard_transform\n",
    "\n",
    "For more example of how to use the **StandardScaler** see the **preprocessing_demo** notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f118ed-f1f7-4861-a97c-26b70e1534a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = pp.StandardScaler(input_cols=scaler_input_cols, output_cols=scaler_output_cols)\n",
    "sss.fit(df_test)\n",
    "sss_udf = sss.get_udf_encoder()\n",
    "sss_encoded_data = ut.udf_standard_transform(array_test, sss_udf)\n",
    "sss_encoded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a74787-ea90-4fa2-8239-ea217aa95872",
   "metadata": {},
   "source": [
    "**udf_standard_inverse_transform** will inverse the scaled data back to original values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4335662-d851-49fa-b9b2-54d94b985864",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.udf_standard_inverse_transform(sss_encoded_data, sss_udf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd40ac0-d38d-43d8-aaeb-4cf2a71a2a80",
   "metadata": {},
   "source": [
    "#### udf_maxabs_transform\n",
    "\n",
    "For more example of how to use the **MaxAbsScaler** see the **preprocessing_demo** notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810a4cb6-cd2d-47b2-a56b-0ce23ef6b173",
   "metadata": {},
   "outputs": [],
   "source": [
    "mas = pp.MaxAbsScaler(input_cols=scaler_input_cols, output_cols=scaler_output_cols)\n",
    "mas.fit(df_test)\n",
    "mas_udf = mas.get_udf_encoder()\n",
    "mas_encoded_data =  ut.udf_maxabs_transform(array_test, mas_udf)\n",
    "mas_encoded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860c5126-ca77-4b1d-ad41-7963483f292c",
   "metadata": {},
   "source": [
    "**udf_maxabs_inverse_transform** will inverse the scaled data back to original values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c5c631-2b2b-4438-a6db-a4a98bc676ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.udf_maxabs_inverse_transform(mas_encoded_data, mas_udf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a10037f-89f1-422f-ae8b-0d0a329bf28c",
   "metadata": {},
   "source": [
    "#### udf_robust_transform\n",
    "\n",
    "For more example of how to use the **RobustScaler** see the **preprocessing_demo** notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b4b20a-7183-4519-bf29-622f53829bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = pp.RobustScaler(input_cols=scaler_input_cols, output_cols=scaler_output_cols)\n",
    "rs.fit(df_test)\n",
    "rs_udf = rs.get_udf_encoder()\n",
    "rs_encoded_data = ut.udf_robust_transform(array_test, rs_udf)\n",
    "rs_encoded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaff50c-755c-4108-8433-4538c8ecaf2d",
   "metadata": {},
   "source": [
    "**udf_robust_inverse_transform** will inverse the scaled data back to original values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc61b3ca-2939-4d2f-a8d1-47de7d7658e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.udf_robust_inverse_transform(rs_encoded_data, rs_udf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188b96a7-baed-416a-9e98-50e106fa878d",
   "metadata": {},
   "source": [
    "#### udf_normalizer_transform\n",
    "\n",
    "For more example of how to use the **Normalizer** see the **preprocessing_demo** notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17624feb-cd8c-4b08-89eb-9edfd475e750",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = pp.Normalizer(input_cols=scaler_input_cols, output_cols=scaler_output_cols)\n",
    "ns.fit(df_test)\n",
    "ns_udf = ns.get_udf_encoder()\n",
    "ut.udf_normalizer_transform(array_test, ns_udf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa2d618-741b-4a93-90cc-528e5a8d2e6a",
   "metadata": {},
   "source": [
    "#### udf_binarizer_transform\n",
    "\n",
    "For more example of how to use the **Binarizer** see the **preprocessing_demo** notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60f9112-f940-4621-b2bf-5f4bec17aeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = pp.Binarizer(input_cols=scaler_input_cols, output_cols=scaler_output_cols)\n",
    "bs.fit(df_test)\n",
    "bs_udf = bs.get_udf_encoder()\n",
    "\n",
    "ut.udf_binarizer_transform(array_test, bs_udf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f93c81-dfd9-40f6-893d-2ed4c6b471fe",
   "metadata": {},
   "source": [
    "### Encoders\n",
    "**udf_transform** has the following functions for Encoders:\n",
    "* udf_ordinal_transform\n",
    "* udf_onehot_transform\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d445337-bed6-4c49-abfa-7b9e1116ac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_cols = [\"STATE\", \"AREA_CODE\", \"INTL_PLAN\"]\n",
    "array_encoder_test = [['KS', 415, 'no'], ['OH', 415, 'no']]\n",
    "array_encoder_unk = [['XX', 415, 'yes'], ['ZZ', 351, 'XY'], ['WI', 351, 'XY']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151bcb68-bb7b-4474-a2ee-bea52387f426",
   "metadata": {},
   "source": [
    "#### udf_onehot_transform\n",
    "\n",
    "For more example of how to use the **OneHotEncoder** see the **preprocessing_demo** notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3776c681-3800-4d15-8fbe-fcca46062e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = pp.OneHotEncoder(input_cols=encoder_input_cols)\n",
    "ohe.fit(df_test)\n",
    "ohe_udf = ohe.get_udf_encoder()\n",
    "ohe_encoded_data = ut.udf_onehot_transform(array_encoder_test, ohe_udf)\n",
    "ohe_encoded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13199df-b1b9-4a10-8ef3-a8a609c8c12e",
   "metadata": {},
   "source": [
    "**udf_onehot_inverse_transform** will inverse the encoded values to the orginal ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96498028-5563-4868-9665-07b4bc6a55ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.udf_onehot_inverse_transform(ohe_encoded_data, ohe_udf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58607ee-eb3b-4b2a-b725-3825a910dd45",
   "metadata": {},
   "source": [
    "The handling of unkown data is the same as with the **OneHotEncoder** **transform** method, it is igonerd by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f041e967-1366-409f-a5d1-ca950c88ca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_unk_encoded_data = ut.udf_onehot_transform(array_encoder_unk, ohe_udf)\n",
    "ohe_unk_encoded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3e21d5-1874-432c-bf80-0b4790462d4b",
   "metadata": {},
   "source": [
    "The udf_onehot_inverse_transform will return None for unkown values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a348aa5c-bd7f-49ac-b623-36d8cb025fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.udf_onehot_inverse_transform(ohe_unk_encoded_data, ohe_udf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a1321c-e2b6-4281-90c7-950f32d20334",
   "metadata": {},
   "source": [
    "If we use **handle_unknown**='keep' then there will be one extra element for each input column for handling unkown values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3c0453-d9ea-43f6-85d1-a71d6de8b66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_keep_unk = pp.OneHotEncoder(input_cols=encoder_input_cols, handle_unknown='keep')\n",
    "ohe_keep_unk.fit(df_test)\n",
    "ohe_keep_unk_udf = ohe_keep_unk.get_udf_encoder()\n",
    "ohe_keep_unk_encoded_data = ut.udf_onehot_transform(array_encoder_unk, ohe_keep_unk_udf)\n",
    "ohe_keep_unk_encoded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6259ed-a29e-44b5-854b-e0ecd62ba84a",
   "metadata": {},
   "source": [
    "Using **udf_onehot_inverse_transform** with **handle_unknown**='keep' will still return None for unkown values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75efdd45-c940-4ee1-ae9c-7486ae2ab787",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.udf_onehot_inverse_transform(ohe_keep_unk_encoded_data, ohe_keep_unk_udf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1344a287-4207-48d2-b3af-6451d6189b57",
   "metadata": {},
   "source": [
    "#### udf_ordinal_transform\n",
    "\n",
    "For more example of how to use the **OrdinalEncoder** see the **preprocessing_demo** notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4bf565-1870-4312-8071-b7d68ae86b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "oe = pp.OrdinalEncoder(input_cols=encoder_input_cols)\n",
    "oe.fit(df_test)\n",
    "oe_udf = oe.get_udf_encoder()\n",
    "oe_encoded_data = ut.udf_ordinal_transform(array_encoder_test, oe_udf)\n",
    "oe_encoded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd3edea-4e4f-48e7-93ef-2e8a37b84702",
   "metadata": {},
   "source": [
    "**udf_ordinal_inverse_transform** will inverse the encoded values to the orginal ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3505f48-01c8-4311-9b7f-0e75596e269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.udf_ordinal_inverse_transform(oe_encoded_data, oe_udf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484401d1-eaab-43d9-a512-272ca42b3089",
   "metadata": {},
   "source": [
    "The handling of unkown data is the same as with the **OrdinalEncoder** **transform** method, it is igonerd by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb7d24c-a2a0-438b-92b4-6b64574159aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "oe_unk_encoded_data = ut.udf_ordinal_transform(array_encoder_unk, oe_udf)\n",
    "oe_unk_encoded_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b151dd0-79a0-44a5-b5b7-c0e0f6ef6919",
   "metadata": {},
   "source": [
    "Equaly for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfa4d75-215f-4c26-8f1c-d328642cd975",
   "metadata": {},
   "outputs": [],
   "source": [
    "array_encoder_unk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c8684-24f6-449a-9c88-1debaaba2c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.udf_ordinal_inverse_transform(oe_unk_encoded_data, oe_udf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c76fe7f-7de2-4d5b-a3e2-9f906ec572fc",
   "metadata": {},
   "source": [
    "If **handle_unknown**=\"use_encoded_value\" then **unknown_value** value will be used for unkown values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac66e72-00ee-4bfc-83fa-955282c71a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "oe_unk = pp.OrdinalEncoder(input_cols=encoder_input_cols, handle_unknown=\"use_encoded_value\", unknown_value=999)\n",
    "oe_unk.fit(df_test)\n",
    "oe_unk_udf = oe_unk.get_udf_encoder()\n",
    "ut.udf_ordinal_transform(array_encoder_unk, oe_unk_udf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d051e96-3ec3-4797-ad19-70f0ed3cbce1",
   "metadata": {},
   "source": [
    "#### udf_label_transform\n",
    "\n",
    "The **udf_label_transform** function expects a list with one element for each row.\n",
    "\n",
    "For more example of how to use the **LabelEncoder** see the **preprocessing_demo** notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14612622-84fa-4a89-81e6-21c0c4acb227",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = [['yes'], ['yes'], ['no']]\n",
    "le = pp.LabelEncoder(input_col=\"INTL_PLAN\", output_col=\"INTL_PLAN_ENCODED\")\n",
    "le.fit(df_test)\n",
    "le_udf = le.get_udf_encoder()\n",
    "\n",
    "ut.udf_label_transform(y_data, le_udf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c66124-904f-484e-aebe-02e9dc8f4e95",
   "metadata": {},
   "source": [
    "## Using the udf transform functions with Python UDF\n",
    "The **udf_transform** functions returns numpy arrays, meaning all UDFs using them need to add the numpy library as a import, and also convert the returned data to a Python list before returning it to Snowflake\n",
    "\n",
    "When using a UDF transformer in a Python UDF there is different ways to deploy it.\n",
    "* By emedding the encoder, returned by **get_udf_encoder** method, as a variable\n",
    "* By providing the encoder, returned by **get_udf_encoder** method, as a parameter to the UDF function\n",
    "* By storing the encoder, returned by **get_udf_encoder** method, as a file and load it in the UDF\n",
    "\n",
    "We can also use a scalar or tabular UDF, depending on how we want the values back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c0b9b3-bc0d-4a03-8591-68f4b7562172",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql('CREATE OR REPLACE STAGE udf_transform_stage').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597238ea-9d9c-4994-80f4-48c5af98d1cc",
   "metadata": {},
   "source": [
    "Starting with creating a scalar UDF function that uses the encoder as a embedded variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad5c157-b95e-4060-ac56-c27838f42f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = mms_udf\n",
    "def minmax_transform(data: list):\n",
    "    import udf_transform as ut\n",
    "    # encoder variable needs to be set outside this function before deploying\n",
    "    return ut.udf_minmax_transform(data, encoder).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e42ab18-f07d-48cb-ac67-317f4ae2097e",
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_minmax = session.udf.register(minmax_transform, \n",
    "                                                 name=\"minmax_transform_udf\",\n",
    "                                                 is_permanent=True,\n",
    "                                                 stage_location='@udf_transform_stage', \n",
    "                                                 imports=[\"udf_transform\"],\n",
    "                                                 packages=[\"numpy\"],\n",
    "                                                 input_types=[T.ArrayType()],\n",
    "                                                 return_type=T.ArrayType(),\n",
    "                                                 replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cbddc4-5385-4db8-9b5b-5e52165b1765",
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_test_df = session.create_dataframe(array_test, schema=scaler_input_cols)\n",
    "udf_test_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa730a5c-6424-4370-96bd-dfa0915198ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_test_df.select(*scaler_input_cols, F.call_udf(\"minmax_transform_udf\", F.array_construct(*scaler_input_cols))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaeaa355-4f44-4fe8-88f8-63afd6aafc4b",
   "metadata": {},
   "source": [
    "If we want the scaled values returned as columns we can use a Tabular UDF.\n",
    "\n",
    "By checking the **input_features** we will get the number of parameters needed for our function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bd4ea3-9c1c-4d15-8002-3dc028a0a2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder['input_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d41acbf-6ebd-48c8-8da3-a962741d9af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class minmax_transform_udtf:\n",
    "    def process(self, calls: int, day_charge:float):\n",
    "        import udf_transform as ut\n",
    "        data = [calls, day_charge]\n",
    "        trans_vals = ut.udf_minmax_transform(data, encoder)\n",
    "        yield tuple(trans_vals)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d702279d-4a2d-4bf5-b5cd-5ff4b0c10729",
   "metadata": {},
   "outputs": [],
   "source": [
    "udtf_minmax = session.udtf.register(minmax_transform_udtf, \n",
    "                                                 name=\"minmax_transform_udtf\",\n",
    "                                                 is_permanent=True,\n",
    "                                                 stage_location='@udf_transform_stage', \n",
    "                                                 imports=[\"udf_transform\"],\n",
    "                                                 packages=[\"numpy\"],\n",
    "                                                 output_schema=T.StructType([T.StructField(\"calls_scaled\", T.FloatType()), T.StructField(\"day_charged_scaled\", T.FloatType())]), \n",
    "                                                 input_types=[T.IntegerType(), T.FloatType()],\n",
    "                                                 replace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67b1291-317a-4429-907c-cb7fe9fd10ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_test_df.join_table_function(udtf_minmax(F.col(\"CALLS\"), F.col(\"DAY_CHARGE\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13a0599-ccf6-41dc-8ebc-37115546cd44",
   "metadata": {},
   "source": [
    "Passing the encoder as a parameter to the UDF function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ec6284-8dd9-4bfd-a3db-bc2e629d20c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_encoder_transform(data: list, udf_encoder: dict):\n",
    "    import udf_transform as ut\n",
    "    return ut.udf_minmax_transform(data, udf_encoder).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9342cbb6-aaab-4803-a1fd-970dbe65d84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_encoder_minmax = session.udf.register(minmax_encoder_transform, \n",
    "                                                 name=\"minmax_encoder_transform_udf\",\n",
    "                                                 is_permanent=True,\n",
    "                                                 stage_location='@udf_transform_stage', \n",
    "                                                 imports=[\"udf_transform\"],\n",
    "                                                 packages=[\"numpy\"],\n",
    "                                                 input_types=[T.ArrayType(), T.VariantType()],\n",
    "                                                 return_type=T.ArrayType(),\n",
    "                                                 replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912cdb8b-12ab-4950-b5ff-dadd8c120fb4",
   "metadata": {},
   "source": [
    "Since the returned object from **get_udf_encoder** is a dictionary object we need to convert it to a JSON string first and then use the **parse_json** finction for passing it into the UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036011fe-389d-4813-8012-0de2c8667823",
   "metadata": {},
   "outputs": [],
   "source": [
    "para_encoder = json.dumps(mms_udf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bbc197-9099-4d71-9e1c-44d307f5f728",
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_test_df.select(*scaler_input_cols, F.call_udf(\"minmax_encoder_transform_udf\", F.array_construct(*scaler_input_cols), F.parse_json(F.lit(para_encoder)))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7dfed6-7148-482f-8fd2-cc672e6fd69e",
   "metadata": {},
   "source": [
    "When reading the encoder from a stage we need to first store it as a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4513ca08-8b35-46e7-9285-9b032ddc3750",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./mms_encoder.json', 'w') as f:\n",
    "    json.dump(mms_udf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58b6935-7d37-4689-a56e-83439cf0f276",
   "metadata": {},
   "source": [
    "The function for the UDF then needs to use the **snowflake_import_directory** setting to get the storage location before reading the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed436bb7-ac1f-4a21-b08b-f731ddb49b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cachetools.cached(cache={})\n",
    "def read_file(filename):\n",
    "    import sys\n",
    "    import os\n",
    "    \n",
    "    import_dir = sys._xoptions.get(\"snowflake_import_directory\")\n",
    "    if import_dir:\n",
    "        encoder_file = import_dir +filename\n",
    "        f = open(encoder_file)\n",
    "        return json.load(f)\n",
    "        \n",
    "def minmax_file_transform(data: list):\n",
    "    import udf_transform as ut\n",
    "\n",
    "    udf_encoder = read_file('mms_encoder.json')\n",
    "    return ut.udf_minmax_transform(data, udf_encoder).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2838d75a-9450-4c67-9540-085f080ea0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_file_minmax = session.udf.register(minmax_file_transform, \n",
    "                                                 name=\"minmax_file_transform\",\n",
    "                                                 is_permanent=True,\n",
    "                                                 stage_location='@udf_transform_stage', \n",
    "                                                 imports=[\"udf_transform\", \"mms_encoder.json\"],\n",
    "                                                 packages=[\"numpy\", \"cachetools\"],\n",
    "                                                 input_types=[T.ArrayType()],\n",
    "                                                 return_type=T.ArrayType(),\n",
    "                                                 replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7ffe29-452b-4e1f-a6e0-e6a98419edcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_test_df.select(*scaler_input_cols, F.call_udf(\"minmax_file_transform\", F.array_construct(*scaler_input_cols))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c0a6d1-9599-4b9c-8dae-58bea3014735",
   "metadata": {},
   "source": [
    "Using encoders with Tabular UDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e03a860-552f-4067-b6ce-8fa8bcfe356e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(oe_udf['input_features'])\n",
    "print(oe_udf['output_cols'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0a8f67-01df-4a40-9acf-8936e9e7859d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ordinal_encode_udtf:\n",
    "    def process(self, state: str, area_code:str, intl_plan: str):\n",
    "        import udf_transform as ut\n",
    "        data = [state, area_code, intl_plan]\n",
    "        trans_vals = ut.udf_ordinal_transform(data, oe_udf)\n",
    "        yield tuple(trans_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c1b692-8716-498d-9a1d-7c90052a23a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "udtf_ordinal = session.udtf.register(ordinal_encode_udtf, \n",
    "                                                 name=\"ordinal_encode_udtf\",\n",
    "                                                 is_permanent=True,\n",
    "                                                 stage_location='@udf_transform_stage', \n",
    "                                                 imports=[\"udf_transform\"],\n",
    "                                                 packages=[\"numpy\"],\n",
    "                                                 output_schema=T.StructType([T.StructField(\"state_ordinal\", T.StringType()), T.StructField(\"area_code_ordinal\", T.StringType()), T.StructField(\"intl_plan_ordinal\", T.StringType())]), \n",
    "                                                 input_types=[T.StringType(), T.StringType(), T.StringType()],\n",
    "                                                 replace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644782b3-3fc7-445b-aa93-338759580fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "udtf_test_df = session.create_dataframe(array_encoder_test, schema=encoder_input_cols)\n",
    "udtf_test_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f26fdc8-f7d7-4f7c-927c-306dc912d343",
   "metadata": {},
   "outputs": [],
   "source": [
    "udtf_test_df.join_table_function(udtf_ordinal(F.col(\"STATE\"), F.to_char(F.col(\"AREA_CODE\")), F.col(\"INTL_PLAN\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe0ba58-d959-442c-a496-4ef16e23c52c",
   "metadata": {},
   "source": [
    "The **OneHotEncoder** usually generates a lot of columns, it is based on the disticnt values found for each column during fit. So instead of typing each column by hand we can loop through **output_cols** field of the UDF encoder to generate the output schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef14e6d5-59cd-4208-8d51-36ed0bb783cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_cols = ohe_udf['output_cols']\n",
    "fields = []\n",
    "for col in output_cols:\n",
    "    for col_nm in output_cols[col]:\n",
    "        fields.append(T.StructField(col_nm, T.StringType()))\n",
    "output_schema = T.StructType(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7afdb3-f9a7-4409-817e-758ff8bdcb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0465ea28-7f74-433d-9fbf-482420fbec40",
   "metadata": {},
   "source": [
    "By checking the **input_features** we will get the number of parameters needed for our function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8df0655-a627-4008-af02-60b8628dc762",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_udf['input_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad495ed3-fcdb-4753-858e-ebab7e40eab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class onehot_encode_udtf:\n",
    "    def process(self, state: str, area_code:str, intl_plan: str):\n",
    "        import udf_transform as ut\n",
    "        data = [state, area_code, intl_plan]\n",
    "        trans_vals = ut.udf_onehot_transform(data, ohe_udf)\n",
    "        yield tuple(trans_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6811d9df-4ce3-4e81-86c7-d695a7e90298",
   "metadata": {},
   "outputs": [],
   "source": [
    "udtf_onehot = session.udtf.register(onehot_encode_udtf, \n",
    "                                                 name=\"onehot_encode_udtf\",\n",
    "                                                 is_permanent=True,\n",
    "                                                 stage_location='@udf_transform_stage', \n",
    "                                                 imports=[\"udf_transform\"],\n",
    "                                                 packages=[\"numpy\"],\n",
    "                                                 output_schema=output_schema, \n",
    "                                                 input_types=[T.StringType(), T.StringType(), T.StringType()],\n",
    "                                                 replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b59fee2-43cb-4fb5-aac6-25994995a85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "udtf_test_df.join_table_function(udtf_onehot(F.col(\"STATE\"), F.to_char(F.col(\"AREA_CODE\")), F.col(\"INTL_PLAN\"))).to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7166d07-5a69-4ac9-b67e-14cea2b8a946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
