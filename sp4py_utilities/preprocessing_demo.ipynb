{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92f0df67-d97c-4af5-b390-b22a58fae681",
   "metadata": {},
   "source": [
    "# perprocessing examples\n",
    "\n",
    "\n",
    "This notebook demostrates how to use the **preprocessing** module of **sp4py_utilities**\n",
    "\n",
    "The purpose of the **preprocessing** module is to provide similar preprocessing functionality using Snowpark DataFrames as the [sklearn.preprocessing](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) module. Having seperated **fit** and **transform** methods enables the possibility to use a fitted scaler/encoder in another pipleine by saving it as a file object. If you want to use a fitted scaler/encoder with Snowflake without using Snowpark DataFrames you can use the functions in the module **udf_transform** for that, see the **udf_transform_demo** notebook for details.\n",
    "\n",
    "Currently the following scalers and encoders are implemented:\n",
    "* MinMaxScaler: Transform each column by scaling each feature to a given range.\n",
    "* StandardScaler: Standardize features by removing the mean and scaling to unit variance.\n",
    "* MaxAbsScaler: Scale each column by its maximum absolute value.\n",
    "* RobustScaler: Scale features using statistics that are robust to outliers.\n",
    "* Normalizer: Normalize individually to unit norm.\n",
    "* Binarizer: Binarize data (set feature values to 0 or 1) according to a threshold.\n",
    "* OneHotEncoder: Encode categorical features as a one-hot.\n",
    "* OrdinalEncoder: Encodes a string column of labels to a column of label indices. The indices are in [0, number of labels].\n",
    "* LabelEncoder: A label indexer that maps a string column of labels to a column of label indices.\n",
    "\n",
    "This notebook has the following sections\n",
    "* Scalers - examples of how to use those\n",
    "* Encoders - examples of how to use those\n",
    "* Using the scalers/encoders in a Python Stored Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f651f02-383b-443a-8981-d98e175e27c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowpark\n",
    "from snowflake.snowpark import Session\n",
    "import snowflake.snowpark.functions as F\n",
    "\n",
    "import joblib\n",
    "import io\n",
    "\n",
    "# Print the version of Snowpark we are using\n",
    "from importlib.metadata import version\n",
    "version('snowflake_snowpark_python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7411a74b-c644-4fbb-bd80-690b62d2334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The preprosessing module\n",
    "import preprocessing as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cf0f87-c3ee-465e-ac6a-c702cf921a28",
   "metadata": {},
   "source": [
    "Connect to Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ba338b-c819-42f0-a8be-d06c14ef44d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_parameters = {\n",
    "    \"account\": \"MY DEMO ACCOUNT\",\n",
    "    \"user\": \"MY USER\",\n",
    "    \"password\": \"MY PASSWORD\",\n",
    "    \"warehouse\": \"MY COMPUTE WH\",\n",
    "    \"database\": \"MY DATABASE\",\n",
    "    \"schema\": \"MY SCHEMA\"\n",
    "}\n",
    "\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "print(\"Current role: \" + session.get_current_role() + \", Current schema: \" + session.get_fully_qualified_current_schema() + \", Current WH: \" + session.get_current_warehouse())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29459ca7-d969-4a16-9d4a-e8a1ebe196a1",
   "metadata": {},
   "source": [
    "Start by creating a dataset that can be used for both scaling and encoding.\n",
    "\n",
    "By caching the result into a new dataframe we avoid running teh generation SQL every time the data frame is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380c2e5b-2bb2-4435-bacd-c50781db8aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = '[\"AK\", \"AL\", \"AR\", \"AZ\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \"FL\", \"GA\", \"HI\", \"IA\", \"ID\", \"IL\", \"IN\", \"KS\", \"KY\", \"LA\", \"MA\", \"MD\", \"ME\", \"MI\", \"MN\", \"MO\", \"MS\", \"MT\", \"NC\", \"ND\", \"NE\", \"NH\", \"NJ\", \"NM\", \"NV\", \"NY\", \"OH\", \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \"VA\", \"VT\", \"WA\", \"WI\", \"WV\", \"WY\"]'\n",
    "area_code = '[408, 415, 510]'\n",
    "intl_plan =  '[\"no\", \"yes\"]'\n",
    "\n",
    "df_gen_data = session.range(1000).with_columns([\"STATES\", \"AREA_CODES\", \"INTL_PLANS\"], \n",
    "                                         [F.parse_json(F.lit(state)), F.parse_json(F.lit(area_code)), F.parse_json(F.lit(intl_plan))])\\\n",
    "                            .select(F.col(\"ID\").as_(\"CUST_ID\"), F.as_varchar(F.get(F.col(\"STATES\"), (F.call_builtin(\"zipf\", F.lit(1), F.lit(51), F.random()) -1))).as_(\"STATE\"),\\\n",
    "                                    F.get(F.col(\"AREA_CODES\"), (F.call_builtin(\"zipf\", F.lit(1), F.lit(3), F.random())) -1).as_(\"AREA_CODE\"),\\\n",
    "                                    F.as_varchar(F.get(F.col(\"INTL_PLANS\"), (F.call_builtin(\"zipf\", F.lit(1), F.lit(2), F.random()))-1)).as_(\"INTL_PLAN\"),\\\n",
    "                                    F.uniform(0, 100, F.random()).as_(\"CALLS\"), F.uniform(0, 100, F.random()).as_(\"MINS\"),F.uniform(0, 100, F.random()).as_(\"DATA\"),\\\n",
    "                                    F.uniform(0.5, 10.9, F.random()).as_(\"DAY_CHARGE\"),F.uniform(5.5, 15.1, F.random()).as_(\"INTL_CHARGE\"))\n",
    "\n",
    "df_test = df_gen_data.cache_result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29e982e-12a3-4925-97de-2a6e89fbafa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7596182-e483-4284-b1ea-8b2892dbc725",
   "metadata": {},
   "source": [
    "## Scalers\n",
    "Since we are going to test diffrent scalers we can set variables for our input columns, ie what columns to scale, and output columns, ie name of the scaled columns\n",
    "\n",
    "If we do not provide input columns then all numeric columns in a Snowpark DataFrame will be used and if we do not provide output columns the scaled columns will replace the input columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74f38b9-d79c-4893-859a-32c9ff2f77eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_input_cols=[\"CALLS\", \"DAY_CHARGE\"]\n",
    "scaler_output_cols = [\"calls_scaled\", \"day_charge_scaled\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42ca833-98ac-4737-97b8-a13e8235ff92",
   "metadata": {},
   "source": [
    "### MinMaxScaler\n",
    "\n",
    "The MinMaxScaler will transform each column by scaling each feature to a given range, default 0-1.\n",
    "\n",
    "After fitting it with a DataFrame (need have the **input_cols** parameter)  we can for example see the what values where fitted by the **fitted_values_** attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba42233b-0a4b-445a-bd28-59d0a45fdda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mms = pp.MinMaxScaler(input_cols=scaler_input_cols, output_cols=scaler_output_cols)\n",
    "mms.fit(df_test)\n",
    "mms.fitted_values_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a7eb88-c9c2-4677-8fca-0a709def0abd",
   "metadata": {},
   "source": [
    "Scale a DataFrame, since we have set **input_cols** and **input_cols** the returning DataFrame will have new columns for the scaled values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70efb60e-2bb1-4358-8584-868e2ddaf9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "mms_tr_df = mms.transform(df_test)\n",
    "mms_tr_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028f8834-28ca-4dd7-aacc-1a1c1ed4a058",
   "metadata": {},
   "source": [
    "We can reverse the scaling by using the **inverse_transform** method. The reversed values will be in the output columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1d0f2e-0ff6-4aec-b952-93a94c12b540",
   "metadata": {},
   "outputs": [],
   "source": [
    "mms.inverse_transform(mms_tr_df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5324776-fbc0-4c2c-b0bb-4c6b286cbd57",
   "metadata": {},
   "source": [
    "We can fit and transform in one go with **fit_transform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a903cd-630e-4602-878c-bc78f083d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "mms.fit_transform(df_test).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ea0942-3311-4c95-8739-6c1932131423",
   "metadata": {},
   "source": [
    "If we want to save the fitted scaler so it can be used in another Python script etc we can do that with pickle or joblib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11d7d83-6b00-4dc3-8480-8687d1d865e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(mms, 'my_min_max_scaler.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90acea31-6ef1-460a-9f76-2979d2f8535b",
   "metadata": {},
   "source": [
    "We can the load it into a new variable and use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b029328a-c47c-4972-9f81-c184e15ca35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_mms = joblib.load('my_min_max_scaler.joblib')\n",
    "loaded_mms.transform(df_test).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cafc76d-3fb1-44d1-83ef-2ad684d93920",
   "metadata": {},
   "source": [
    "By default the feature range used is 0-1 but that can be changed with the **feature_range** parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83282640-c77f-4174-83c8-f3a202087a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.MinMaxScaler(input_cols=scaler_input_cols, output_cols=scaler_output_cols, feature_range=(1,2)).fit_transform(df_test).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52d3d92-7eed-491a-af58-ec6d9a82f90e",
   "metadata": {},
   "source": [
    "Transform new data with the previous fitted scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f7be92-fde7-4411-955d-3982903bec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_data = session.create_dataframe([[56, 1.987], [32, 9.689]], schema=scaler_input_cols)\n",
    "df_new_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f9cf42-9db8-4cc8-a97c-0e27144e0a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mms.transform(df_new_data).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5424294-26bc-42e0-9123-17f48fa002b7",
   "metadata": {},
   "source": [
    "### StandardScaler\n",
    "\n",
    "Standardize features by removing the mean and scaling to unit variance.\n",
    "\n",
    "By default it center the data before scaling and scale the data to unit standard deviation.\n",
    "\n",
    "How to save a fitted scaler to be used later see the MinMaxScaler examples above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466f2a9a-ed85-4e1d-8d28-eba9658eff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = pp.StandardScaler(input_cols=scaler_input_cols, output_cols=scaler_output_cols)\n",
    "sss.fit(df_test)\n",
    "sss.fitted_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea5e279-f87a-4690-856b-253803d78937",
   "metadata": {},
   "outputs": [],
   "source": [
    "sss_tr_df = sss.transform(df_test)\n",
    "sss_tr_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9071aa-91fe-4fb8-8e95-4e80eb42d018",
   "metadata": {},
   "source": [
    "We can reverse the scaling by using the **inverse_transform** method. The reversed values will be in the output columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d580148f-f10c-48c1-b71c-afe1a2ff888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sss.inverse_transform(sss_tr_df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2d2896-21eb-428e-bc97-90c9ceade93c",
   "metadata": {},
   "source": [
    "Setting **with_mean**=False will disable the centering of data before scaling. With **with_std**=True the data will be scaled to unit standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d11bcda-5225-4762-99a6-644ead13cbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.StandardScaler(input_cols=scaler_input_cols, output_cols=scaler_output_cols, with_mean=False, with_std=True).fit_transform(df_test).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec15825-f363-47ab-9822-da28a0bdc8c0",
   "metadata": {},
   "source": [
    "Setting **with_std**=False will disable the scaling of the data to unit standard deviation. With **with_mean**=True the data will only be centered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c88e142-cd73-488a-9385-21a08a1d5072",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.StandardScaler(input_cols=scaler_input_cols, output_cols=scaler_output_cols, with_mean=True, with_std=False).fit_transform(df_test).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5c31d2-52ab-4f87-9e98-89352f6a3bb3",
   "metadata": {},
   "source": [
    "Setting both **with_mean** and **with_std** to False will return the same values as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ea252f-109f-443b-b145-a42ffecc466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.StandardScaler(input_cols=scaler_input_cols, output_cols=scaler_output_cols, with_mean=False, with_std=False).fit_transform(df_test).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a07e061-469e-4d62-8db2-8cba02ccaad7",
   "metadata": {},
   "source": [
    "### MaxAbsScaler\n",
    "\n",
    "Scale each column by its maximum absolute value.\n",
    "\n",
    "How to save a fitted scaler to be used later see the MinMaxScaler examples above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd2d82b-fca1-4806-9a84-54974ef67bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mas = pp.MaxAbsScaler(input_cols=scaler_input_cols, output_cols=scaler_output_cols)\n",
    "mas.fit(df_test)\n",
    "mas.fitted_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df597fa8-9e46-417c-9e05-3c0d6cf376a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mas_tr_df = mas.transform(df_test)\n",
    "mas_tr_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72155db3-05b3-4b86-bc91-b2d0cbf5fda9",
   "metadata": {},
   "source": [
    "We can reverse the scaling by using the **inverse_transform** method. The reversed values will be in the output columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90c0416-3524-41be-aeb7-33d9c9f062a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mas.inverse_transform(mas_tr_df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32771251-7501-4e89-ba34-9b8347df6308",
   "metadata": {},
   "source": [
    "### RobustScaler\n",
    "Scale columns using statistics that are robust to outliers.\n",
    "\n",
    "This scaler scales by remove the median and scales the data according to the quantile range (defaults to IQR: Interquartile Range) The IQR is the range between the 1st quartile (25th quantile) and the 3rd quartile (75th quantile).\n",
    "\n",
    "By default it center the data before scaling and scale the data to interquartile range.\n",
    "\n",
    "How to save a fitted scaler to be used later see the MinMaxScaler examples above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438d4e04-02ee-4e72-8f36-79f839f0473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = pp.RobustScaler(input_cols=scaler_input_cols, output_cols=scaler_output_cols)\n",
    "rs.fit(df_test)\n",
    "rs.fitted_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c98251-42e4-4ca3-85a8-2bed1e795522",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_tr_df = rs.transform(df_test)\n",
    "rs_tr_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78202017-0e9d-458b-9c3c-724ec61f60d3",
   "metadata": {},
   "source": [
    "We can reverse the scaling by using the **inverse_transform** method. The reversed values will be in the output columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba551ba7-2e17-418a-806c-2d5dd56fc9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs.inverse_transform(rs_tr_df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bf0173-cca5-4aca-9b0e-f51436fd52ab",
   "metadata": {},
   "source": [
    "Setting **with_centering**=False will disable centering of data before scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a04f18-f748-401d-bdd3-40817a2a19a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.RobustScaler(input_cols=scaler_input_cols, output_cols=scaler_output_cols, with_centering=False).fit_transform(df_test).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b31c9a-58ba-4f81-ab3e-4cd694678642",
   "metadata": {},
   "source": [
    "Setting **with_scaling**=False will disable scaling of the data to interquartile range before scaling the data to interquartile range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac577a3-c396-4cb8-9295-301adcd80bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.RobustScaler(input_cols=scaler_input_cols, output_cols=scaler_output_cols, with_centering=True, with_scaling=False).fit_transform(df_test).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc6ca9a-a540-45ab-beb8-f761d94b27a9",
   "metadata": {},
   "source": [
    "Setting both **with_centering** and **with_scaling** to False will return unchanged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e11b35-95d6-448e-8002-d05357fd4351",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.RobustScaler(input_cols=scaler_input_cols, output_cols=scaler_output_cols, with_centering=False, with_scaling=False).fit_transform(df_test).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a087ed0-e23b-4c48-83cb-7df818347f99",
   "metadata": {},
   "source": [
    "Using 10th and 90th quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639fdf5d-7979-4b28-9c8f-6dcd9894dc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.RobustScaler(input_cols=scaler_input_cols, output_cols=scaler_output_cols,quantile_range=(10.0, 90.0)).fit_transform(df_test).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c4263d-2fe2-44ae-ba9c-688ad335d691",
   "metadata": {},
   "source": [
    "Setting **unit_variance**=True will scale data so that normally distributed features have a variance of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642189a9-4216-44eb-ba41-de5e30122429",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.RobustScaler(input_cols=scaler_input_cols, output_cols=scaler_output_cols,unit_variance=True).fit_transform(df_test).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5749ef-755d-4db4-b573-a3885b88f718",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Normalizer\n",
    "\n",
    "Normalize individually to unit norm, the Normalizer does not have a inverse transformation method since the transformation values are calculated row by row.\n",
    "\n",
    "The norm to use to normalize each non zero data, l1, l2 or max, l2 is used default.  \n",
    "The l1 norm is calculated as the sum of the absolute values of each column and row.  \n",
    "The l2 norm is calculated as the square root of the sum of the squared column values and row.  \n",
    "The max norm is calculated as the maximum value of the absolute values by column and row.\n",
    "\n",
    "How to save a fitted scaler to be used later see the MinMaxScaler examples above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835e4b2d-9ba4-46db-b704-c6e3a1704008",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = pp.Normalizer(input_cols=scaler_input_cols, output_cols=scaler_output_cols)\n",
    "ns.fit(df_test)\n",
    "ns.fitted_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f596fe-f0e3-45a6-90d8-b2e936bf551f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns_tr_df = ns.transform(df_test)\n",
    "ns_tr_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752f6534-f855-482e-9fcb-caeab663b7ea",
   "metadata": {},
   "source": [
    "l1 norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecaafce-3d46-4a7e-b1a4-684a42831800",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.Normalizer(input_cols=scaler_input_cols, output_cols=scaler_output_cols, norm=\"l1\").fit_transform(df_test).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df35e52a-39b7-4bf8-8c8e-b7e84e447016",
   "metadata": {},
   "source": [
    "max norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eba60a0-c4e5-4e98-9d79-688cf3670620",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.Normalizer(input_cols=scaler_input_cols, output_cols=scaler_output_cols, norm=\"max\").fit_transform(df_test).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f93b76-fc90-40b5-acf8-adde10539f51",
   "metadata": {},
   "source": [
    "### Binarizer\n",
    "\n",
    "Binarize data (set feature values to 0 or 1) according to a threshold, default 0.0.\n",
    "\n",
    "The Binarizer does not have a inverse transform method.\n",
    "\n",
    "How to save a fitted scaler to be used later see the MinMaxScaler examples above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b655e8f9-5164-4f71-8384-5e4d11ddb37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = pp.Binarizer(input_cols=scaler_input_cols, output_cols=scaler_output_cols)\n",
    "bs.fit(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307fde11-4117-4183-a430-3608b18ddae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_tr_df = bs.transform(df_test)\n",
    "bs_tr_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caab6406-45df-4e28-a262-96797a1e60af",
   "metadata": {},
   "source": [
    "Threashold 9.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b982e6-5c1f-4114-98ff-393ac3345e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.Binarizer(input_cols=scaler_input_cols, output_cols=scaler_output_cols, threshold=9.5).fit_transform(df_test).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc59b793-3f0e-44a7-a142-64130350d87a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Encoders\n",
    "\n",
    "Start by setting what columns to use for encoding, if none are provided all columns in a DataFrame will be used.\n",
    "\n",
    "Output columns are created automatically if **categories**=\"auto\" otherwise a category column mapping needs to be providedwith the **categories** parameter.\n",
    "\n",
    "We are also generating a Snowpark DataFrame with unkown values to demo how that can be handled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d609b0ce-3af3-40ce-bc47-30fd994d88bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_cols = [\"STATE\", \"AREA_CODE\", \"INTL_PLAN\"]\n",
    "df_unknown = session.create_dataframe([['XX', 415, 'yes'], ['ZZ', 351, 'XY']], schema=encoder_input_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f834eb-3137-4287-93eb-aef41ac26d03",
   "metadata": {},
   "source": [
    "### OneHotEncoder\n",
    "Encode categorical features as a one-hot, for each input column a new column for each category is created.\n",
    "\n",
    "How to save a fitted encoder to be used later see the MinMaxScaler examples above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f86f2fb-9faf-40ff-b900-b9fa55d92512",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = pp.OneHotEncoder(input_cols=encoder_input_cols)\n",
    "ohe.fit(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962e74d5-51a9-456c-89fc-1cafd000bb6e",
   "metadata": {},
   "source": [
    "By default the input columns are dropped from the returning DataFrame during transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de392b54-1303-438b-b146-97cf940422e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_tr_df = ohe.transform(df_test)\n",
    "ohe_tr_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10822773-9dbb-49e0-bc63-ac5f0423dd76",
   "metadata": {},
   "source": [
    "**inverse_transform** will return the original columns and drop the output columns from the returned DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ec9c1b-227a-4c24-8546-c76c256006d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.inverse_transform(ohe_tr_df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88ca553-9a50-44c5-90d6-be1af0a642bd",
   "metadata": {},
   "source": [
    "Setting **drop_input_cols**=False will keep input columns in the returned DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa449096-36b0-4e33-9859-516def4f3b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_keep_input = pp.OneHotEncoder(input_cols=encoder_input_cols, drop_input_cols=False)\n",
    "ohe_keep_input_tr_df = ohe_keep_input.fit_transform(df_test)\n",
    "ohe_keep_input_tr_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d89a52f-7dc3-40fe-aa72-b87a3f48adf1",
   "metadata": {},
   "source": [
    "**inverse_transform** will behave the same, even with **drop_input_cols**=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077b86c7-0cfd-4474-b040-bfe547ea52a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_keep_input.inverse_transform(ohe_keep_input_tr_df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf14a540-5f6e-498f-9d5e-89be163d3d06",
   "metadata": {},
   "source": [
    "By default unkown values, ie values that was not present duing the fit, is ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37efb33-fc5c-4962-954f-e79c0c91c773",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_ignore_unk = pp.OneHotEncoder(input_cols=encoder_input_cols, drop_input_cols=False)\n",
    "ohe_ignore_unk.fit(df_test)\n",
    "ohe_keep_ignore_tr_df = ohe_ignore_unk.transform(df_unknown)\n",
    "ohe_keep_ignore_tr_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339c0a70-1492-490b-94b4-46f6ac9fd67b",
   "metadata": {},
   "source": [
    "With **inverse_transform** unkown values will be NULL in the returning DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46344600-c8be-488a-a290-de34b4b7466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_ignore_unk.inverse_transform(ohe_keep_ignore_tr_df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c732432-65d6-479c-beb6-cadb8f115b53",
   "metadata": {},
   "source": [
    "Setting **handle_unknown**='keep' will create a unkown column for each feature that is set for 1 for all new values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df539cd-8cf1-4976-9398-5ddfa9457984",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_keep_unk = pp.OneHotEncoder(input_cols=encoder_input_cols, handle_unknown='keep', drop_input_cols=False)\n",
    "ohe_keep_unk.fit(df_test)\n",
    "ohe_keep_unk_tr_df = ohe_keep_unk.transform(df_unknown)\n",
    "ohe_keep_unk_tr_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c62cd6-6d11-4659-9e4e-2aa1fca77ae8",
   "metadata": {},
   "source": [
    "**inverse_transform** with unkown and  handle_unknown='keep' will return NULL for the unkown values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88198a50-506a-4515-8c91-eec10d741f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_keep_unk.inverse_transform(ohe_keep_unk_tr_df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e82687-7daa-4d29-99e9-d2aa3c6a84d0",
   "metadata": {},
   "source": [
    "Column category mapping can be set manual by providing a dictonary to the **categories** parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f01386b-7328-41a5-bcf2-2209b3f46ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_categories = {\"AREA_CODE\": ['408', '415', '510'], \"INTL_PLAN\": ['no', 'yes']}\n",
    "\n",
    "pp.OneHotEncoder(input_cols=['AREA_CODE', 'INTL_PLAN'], categories=my_categories).fit_transform(df_test).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bb0770-46a2-438a-982b-5a9c9995617c",
   "metadata": {},
   "source": [
    "Output columns can be set by using the **output_cols** parameter, since the categories are always sorted in alphabetical order the columns needs to be in the same order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0606a1e-ea97-4052-b19c-728ec4ce69d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_output_cols = {\"AREA_CODE\": ['AC_1', 'AC_2', 'AC_3'], \"INTL_PLAN\": ['NO_PLAN', 'HAS_PLAN']}\n",
    "\n",
    "pp.OneHotEncoder(input_cols=['AREA_CODE', 'INTL_PLAN'], output_cols=my_output_cols, drop_input_cols=False).fit_transform(df_test).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e081329-9f19-4b99-af00-c455a05e8ba6",
   "metadata": {},
   "source": [
    "### OrdinalEncoder\n",
    "\n",
    "Encodes a string column of labels to a column of label indices. The indices are in [0, number of labels].\n",
    "\n",
    "By default, the labels are sorted alphabetically and numeric columns is cast to string.\n",
    "\n",
    "How to save a fitted encoder to be used later see the MinMaxScaler examples above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3125cf8a-df4d-47f7-a09e-de6a93faa99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "oe = pp.OrdinalEncoder(input_cols=encoder_input_cols)\n",
    "oe.fit(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79552dd7-93c8-441c-9181-3ec5209690e7",
   "metadata": {},
   "source": [
    "If not providing output_cols the input_cols witll be replace by the encoded values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745c2fb5-e551-4cdb-8b2c-575bb4a9fda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "oe_tr_df = oe.transform(df_test)\n",
    "oe_tr_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87fad85-8327-47fa-b003-5a953679b53a",
   "metadata": {},
   "source": [
    "By setting output_cols the transformed DataFrame will also keep the input columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc2b509-1fd9-4d06-8297-c5e544f4f724",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.OrdinalEncoder(input_cols=encoder_input_cols, output_cols=[\"STATE_ENCODED\", \"AREA_CODE_ENCODED\", \"INTL_PLAN_ENCODED\"]).fit_transform(df_test).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c8e2fc-d31b-44f5-a913-ab919a841bd3",
   "metadata": {},
   "source": [
    "By default unkown values, ie values that was not present duing the fit, will get NULL in the encoded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90b2642-722f-4d24-a96d-87cdc8d7f417",
   "metadata": {},
   "outputs": [],
   "source": [
    "oe_ignore_unk = pp.OrdinalEncoder(input_cols=encoder_input_cols, output_cols=[\"STATE_ENCODED\", \"AREA_CODE_ENCODED\", \"INTL_PLAN_ENCODED\"])\n",
    "oe_ignore_unk.fit(df_test)\n",
    "oe_keep_ignore_tr_df = oe_ignore_unk.transform(df_unknown)\n",
    "oe_keep_ignore_tr_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86660e5-21ba-4484-88a3-71f76bcc54e4",
   "metadata": {},
   "source": [
    "Inverse transform on a transformed DataFrame with unkown values will return NULL values for those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547d6dd3-b1fd-447a-bdc1-e9a4ee8a98ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "oe_ignore_unk.inverse_transform(oe_keep_ignore_tr_df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33082991-fa8d-4991-867a-2af5eca8978d",
   "metadata": {},
   "source": [
    "Setting handle_unknown='use_encoded_value' will replace unkown values with the value of unknown_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112589c4-1f77-4985-b71f-ab3ca9201ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "oe_handle_unk = pp.OrdinalEncoder(input_cols=encoder_input_cols, output_cols=[\"STATE_ENCODED\", \"AREA_CODE_ENCODED\", \"INTL_PLAN_ENCODED\"], handle_unknown='use_encoded_value', unknown_value=999)\n",
    "oe_handle_unk.fit(df_test)\n",
    "oe_handle_ignore_tr_df = oe_handle_unk.transform(df_unknown)\n",
    "oe_handle_ignore_tr_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3e9802-af89-4a19-8353-a466ecc21e3e",
   "metadata": {},
   "source": [
    "Inverse transform on a transformed DataFrame with unkown values will return NULL values for those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59e1f29-2196-474e-87cb-e2c85d337ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "oe_handle_unk.inverse_transform(oe_handle_ignore_tr_df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1a931b-5e81-4be8-a3fc-3f8013f73e0c",
   "metadata": {},
   "source": [
    "### LabelEncoder\n",
    "\n",
    "A label indexer that maps a string column of labels to a column of label indices. The indices are in [0, number of labels].\n",
    "\n",
    "The LabelEncoder is to be used with the target column, for features **OrdinalEncoder** should be used.\n",
    "\n",
    "How to save a fitted encoder to be used later see the MinMaxScaler examples above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f19319-68f8-4175-be1c-b2a6b3cb7f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = pp.LabelEncoder(input_col=\"INTL_PLAN\", output_col=\"INTL_PLAN_ENCODED\")\n",
    "le.fit(df_test)\n",
    "le_tr_df = le.transform(df_test)\n",
    "le_tr_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fa7ca0-8f79-40f1-99b5-dd1353f137bb",
   "metadata": {},
   "source": [
    "**inverse_transform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679ef7de-7ce1-4e6a-b6df-ce8de387b3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "le.inverse_transform(le_tr_df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbadf5a5-9b20-4fb6-a69c-978e0eaff9d8",
   "metadata": {},
   "source": [
    "## Using a scaler in a Python Stored Procedure\n",
    "\n",
    "The following is an example of how a preprocessing scaler can be used in a Python Stored Procedure, the example is depened on that the testdata generation part has been done.\n",
    "\n",
    "The stored Procedure will fit and transform a input tbale using the MinMaxScaler using the **input_cols** and then stored the transformed data in the **output_table**. It will stored the fitted scaler as a joblib object on the stage SP_STAGE.\n",
    "\n",
    "Start by creating the satge where we store the fitted scaler object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a03fb39-a724-475b-8a5d-59047e68da74",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql('CREATE OR REPLACE STAGE SP_STAGE').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8f1c4f-bba4-47ea-8918-8517664f915d",
   "metadata": {},
   "source": [
    "Create a helper function for ssaving the fitted scaler and then the primary function for the stored procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a941b60a-9747-4a7a-aa86-52303442dff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(session, model, path):\n",
    "    input_stream = io.BytesIO()\n",
    "    joblib.dump(model, input_stream)\n",
    "    session._conn._cursor.upload_stream(input_stream, path)\n",
    "    return \"successfully created file: \" + path\n",
    "\n",
    "def min_max_scaler(session: Session, input_table: str, input_cols: list, output_table: str, output_cols: list) -> str:\n",
    "    import preprocessing as pp\n",
    "\n",
    "    df_input = session.table(input_table)\n",
    "    \n",
    "    mms = pp.MinMaxScaler(input_cols=input_cols, output_cols=output_cols)\n",
    "    mms.fit(df_input)\n",
    "    \n",
    "    mms_tr_df = mms.transform(df_input)\n",
    "    \n",
    "    save_file(session, mms, \"@SP_STAGE/min_max_scaler.joblib\")\n",
    "    mms_tr_df.write.mode(\"overwrite\").save_as_table(output_table)\n",
    "    \n",
    "    return \"SUCCESS\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1beaab-6eeb-4c97-9cd1-0bab09ea12d3",
   "metadata": {},
   "source": [
    "Add the imports and deploy the temporary stored procedure function to Snowflake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37072cfa-d0c3-4647-9edc-04272723c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.clear_imports()\n",
    "session.clear_packages()\n",
    "session.add_import(\"preprocessing\")\n",
    "session.add_packages('snowflake-snowpark-python', 'joblib', 'scipy', 'numpy')\n",
    "\n",
    "min_max_scaler_sp = F.sproc(min_max_scaler, replace=True, is_permanent=False, session=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7aa91d-7d9c-40e0-a3c9-81d0113bb8db",
   "metadata": {},
   "source": [
    "Store the test data as a table in Snowflake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163f3a95-c46c-45b9-95b2-5d8b4dea79cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.write.mode(\"overwrite\").save_as_table(\"scaler_input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5571e7ae-3958-40cb-b848-ddb90606966b",
   "metadata": {},
   "source": [
    "Call the stored procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99fc5e4-1345-45bc-8760-5f530da0c8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler_sp(\"scaler_input\", [\"CALLS\", \"DAY_CHARGE\"], \"scaler_output\", [\"calls_scaled\", \"day_charge_scaled\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b00bfbc-7ac4-4ecf-aa16-6cd99de9d9da",
   "metadata": {},
   "source": [
    "Verify that the transformed data is in the **output_table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb14ab80-5e7c-478d-b214-212188a55bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.table(\"scaler_output\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e002ad2-de56-4d57-9c8c-fdcf6b346737",
   "metadata": {},
   "source": [
    "Verify that the fittedscaler is stored on the stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83039fa2-a072-4a95-bbee-401aa46814f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.sql(\"ls @SP_STAGE\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8012025c-4d7d-4e48-a1c1-dcfac60ab53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364527db-f219-4777-9450-57e9bcaca737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
